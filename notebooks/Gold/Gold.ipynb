{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b11aece9-e88c-44ef-85b7-c9705af8cbcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define table configurations\n",
    "tables = {\n",
    "    \"promotion\": \"promotion/\",\n",
    "    \"item\": \"items/\",\n",
    "    \"sales\": \"sales/\",\n",
    "    \"supermarkets\": \"supermarkets/\"  \n",
    "}\n",
    "\n",
    "base_path = \"/mnt/silver/\"\n",
    "\n",
    "# Create dataframes and views in a loop\n",
    "dataframes = {}\n",
    "for table_name, folder in tables.items():\n",
    "    df = (\n",
    "        spark.read\n",
    "        .option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .option(\"multiLine\", True)\n",
    "        .parquet(f\"{base_path}{folder}\")\n",
    "    )\n",
    "    \n",
    "    # Store in dictionary for later use\n",
    "    dataframes[table_name] = df\n",
    "    \n",
    "    # Create temp view\n",
    "    df.createOrReplaceTempView(table_name)\n",
    "    \n",
    "    print(f\"Created view: {table_name}\")\n",
    "\n",
    "\n",
    "promotion_df = dataframes[\"promotion\"]\n",
    "item_df = dataframes[\"item\"]\n",
    "sales_df = dataframes[\"sales\"]\n",
    "supermarkets_df = dataframes[\"supermarkets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd9c87b-f3cd-4f82-8ebe-f9561b3bfeb3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760627863223}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    -- SALES/TEMPORAL FEATURES\n",
    "      S.code\n",
    "    , S.supermarket\n",
    "    , S.week\n",
    "    , S.province\n",
    "    , S.amount AS sales_amount\n",
    "    , S.units AS sales_units\n",
    "    , S.hour_sin\n",
    "    , S.hour_cos\n",
    "    , S.voucher\n",
    "    , S.province_1\n",
    "    , S.province_2\n",
    "    , S.cycle_day_1\n",
    "    , S.cycle_day_2\n",
    "    , S.cycle_day_3\n",
    "    , S.cycle_day_4\n",
    "    , S.cycle_day_5\n",
    "    , S.cycle_day_6\n",
    "    , S.cycle_day_7\n",
    "\n",
    "    -- ITEM FEATURES (Now including the guaranteed type_indexed)\n",
    "    , I.descrption\n",
    "    , I.size_value\n",
    "    , I.size_unit_encoded\n",
    "    , I.brand_indexed\n",
    "    , I.type_indexed -- This column is now guaranteed to exist\n",
    "\n",
    "    -- SUPERMARKET FEATURES\n",
    "    , SM.postal_code_indexed\n",
    "\n",
    "    -- PROMOTION FEATURES (Now including the guaranteed display_indexed)\n",
    "    , P.feature_indexed AS promo_feature_indexed\n",
    "    , P.display_indexed AS promo_display_indexed\n",
    "\n",
    "FROM\n",
    "    sales S\n",
    "\n",
    "LEFT JOIN\n",
    "    item I ON S.code = I.code\n",
    "\n",
    "LEFT JOIN\n",
    "    supermarkets SM ON S.supermarket = SM.supermarket\n",
    "\n",
    "LEFT JOIN\n",
    "    promotion P ON \n",
    "        S.code = P.code AND\n",
    "        S.supermarket = P.supermarkets \n",
    "\n",
    "WHERE P.feature_indexed is not null\n",
    "\"\"\")\n",
    "\n",
    "print(\"--- Final Gold Layer DataFrame Schema (From Spark SQL) ---\")\n",
    "#gold_df.printSchema()\n",
    "display(gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "308d0ccb-7959-4bea-98be-41861545f7d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "write parquet to adls"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"/mnt/gold/gold/\"\n",
    "\n",
    "gold_df.write.parquet(\n",
    "    output_path,\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
