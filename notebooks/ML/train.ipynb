{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df426ebe-12e0-4181-a28c-f5a79d246d5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"multiLine\", True)\n",
    "    .parquet(\"/mnt/gold/gold/\")\n",
    ")\n",
    "#display(gold_df)\n",
    "gold_df.createOrReplaceTempView(\"gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1b78969-f645-4e52-9e2d-7ce44c1b94b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# --- Define ALL Feature Columns ---\n",
    "feature_cols = [\n",
    "    # Sales/Temporal Features\n",
    "    \"hour_sin\", \"hour_cos\", \n",
    "    \"voucher\",\n",
    "    \"province_1\", \"province_2\", \n",
    "    \"cycle_day_1\", \"cycle_day_2\", \"cycle_day_3\", \"cycle_day_4\",\n",
    "    \"cycle_day_5\", \"cycle_day_6\", \"cycle_day_7\",\n",
    "    \n",
    "    # Item Features (Where the NaN is likely coming from due to failed extraction or join)\n",
    "    \"size_value\",\n",
    "    \"size_unit_encoded\", \n",
    "    \"brand_indexed\",     \n",
    "    \"type_indexed\",      \n",
    "    \n",
    "    # Supermarket/Promotion Features\n",
    "    \"postal_code_indexed\", \n",
    "    \"promo_feature_indexed\",\n",
    "    \"promo_display_indexed\"\n",
    "]\n",
    "\n",
    "# Fill NaNs with 0\n",
    "fill_cols = [c for c in feature_cols if c != \"size_unit_encoded\"] # Exclude vector types from direct fill\n",
    "\n",
    "# Fill numerical columns with 0\n",
    "gold_df_clean = gold_df.na.fill(0, subset=fill_cols) \n",
    "\n",
    "#  Assemble the vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "vector_df = assembler.transform(gold_df_clean)\n",
    "\n",
    "# Final Data Selection and Splitting\n",
    "final_ml_df = vector_df.select(\n",
    "    col(\"sales_amount\").alias(\"label\"), # The target variable\n",
    "    col(\"features\")                      # The predictor vector\n",
    ")\n",
    "\n",
    "# Split the data (80% Train, 20% Test)\n",
    "seed_value = 42\n",
    "train_df, test_df = final_ml_df.randomSplit([0.8, 0.2], seed=seed_value)\n",
    "\n",
    "print(f\" Data Vectorized and Split. Training Count: {train_df.count()}, Testing Count: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -5780829113847749,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eee38a3-31f9-4aaa-a834-f965598eac20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the Model ---\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    labelCol=\"label\", \n",
    "    featuresCol=\"features\", \n",
    "    numTrees=100, # Number of trees in the forest\n",
    "    maxDepth=5,   # Maximum depth of the trees (for speed/overfitting control)\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Random Forest Regressor ---\")\n",
    "# --- 2. Train the Model ---\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# --- 3. Make Predictions on the Test Set ---\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "# --- 4. Evaluate the Model ---\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\" # Root Mean Squared Error\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"r2\" # R-squared\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(\"\\n--- Model Evaluation Results (Test Set) ---\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "# Optional: Show a sample of predictions vs. actual sales amount\n",
    "predictions.na.fill(0).select(\"label\", \"prediction\").limit(5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5860a714-ff29-4193-a075-fc19eb24f45b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1e0c71b-cfc8-4008-b51e-8179c301fb58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rf_model.write().overwrite().save(\"/mnt/model/sales_rf_model_v1\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
