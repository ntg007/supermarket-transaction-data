{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d4a4253-05f4-4174-be16-0b0a5b3a126b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "class TestSupermarketsNotebook(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = SparkSession.builder.master(\"local[2]\").appName(\"SupermarketsTest\").config(\"spark.sql.shuffle.partitions\", \"1\").getOrCreate()\n",
    "        # Sample data mimicking raw supermarkets input\n",
    "        data = [\n",
    "            (1001, \"Supermarket A\", \"46220\"),\n",
    "            (1002, \"Supermarket B\", None),                 # Missing postal_code to test null fill\n",
    "            (1003, \"Supermarket C\", \"46222\")\n",
    "        ]\n",
    "        cols = [\"supermarketNo\", \"supermarket\", \"postal-code\"]\n",
    "        cls.df = cls.spark.createDataFrame(data, cols)\n",
    "    \n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.spark.stop()\n",
    "\n",
    "    def test_column_renames_and_casts(self):\n",
    "        df = self.df\n",
    "        \n",
    "        # Rename supermarketNo to supermarket and postal-code to postalcode cast to string\n",
    "        df = df.withColumnRenamed(\"supermarketNo\", \"supermarket\")\n",
    "        df = df.withColumn(\"postalcode\", col(\"postal-code\").cast(\"string\"))\n",
    "\n",
    "        # Fill null postalcode with \"UNKNOWN\"\n",
    "        df = df.fillna(\"UNKNOWN\", subset=[\"postalcode\"])\n",
    "        \n",
    "        # Check column renames\n",
    "        self.assertTrue(\"supermarket\" in df.columns)\n",
    "        self.assertTrue(\"postalcode\" in df.columns)\n",
    "        self.assertFalse(\"supermarketNo\" in df.columns)\n",
    "        self.assertFalse(\"postal-code\" in df.columns)\n",
    "        \n",
    "        # Check postalcode fill for missing value\n",
    "        postalcodes = df.select(\"postalcode\").rdd.flatMap(lambda x: x).collect()\n",
    "        self.assertIn(\"UNKNOWN\", postalcodes)\n",
    "\n",
    "    def test_postalcode_string_indexing(self):\n",
    "        from pyspark.ml.feature import StringIndexer\n",
    "        \n",
    "        df = self.df\n",
    "        df = df.withColumnRenamed(\"supermarketNo\", \"supermarket\")\n",
    "        df = df.withColumn(\"postalcode\", col(\"postal-code\").cast(\"string\"))\n",
    "        df = df.fillna(\"UNKNOWN\", subset=[\"postalcode\"])\n",
    "\n",
    "        indexer = StringIndexer(inputCol=\"postalcode\", outputCol=\"postalcode_indexed\", handleInvalid=\"keep\")\n",
    "        model = indexer.fit(df)\n",
    "        df_indexed = model.transform(df)\n",
    "\n",
    "        # Check that postalcode_indexed is added\n",
    "        self.assertIn(\"postalcode_indexed\", df_indexed.columns)\n",
    "\n",
    "        # Check the indexed column is numeric\n",
    "        types = dict(df_indexed.dtypes)\n",
    "        self.assertEqual(types[\"postalcode_indexed\"], \"double\")\n",
    "\n",
    "if __name__ == \"__main__\":    unittest.main(argv=[''], exit=False)\n",
    "\n",
    "unittest.main()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "supermarkets_test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
