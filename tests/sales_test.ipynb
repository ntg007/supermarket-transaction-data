{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c02a2e-84cd-42b9-8797-eb4e2df1a3af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "class TestSalesDataProcessing(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = SparkSession.builder.master(\"local[2]\").appName(\"SalesTest\").getOrCreate()\n",
    "        # Load or create a sample DataFrame similar to your salesdf for testing\n",
    "        data = [\n",
    "            (11100, 1, 2),  # (time, province, code)\n",
    "            (11323, 2, 3),\n",
    "            (11415, 1, 4)\n",
    "        ]\n",
    "        columns = [\"time\", \"province\", \"code\"]\n",
    "        cls.df = cls.spark.createDataFrame(data, columns)\n",
    "    \n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.spark.stop()\n",
    "    \n",
    "    def test_province_encoding(self):\n",
    "        # Apply your province encoding logic to self.df here or import from your notebook\n",
    "        df = self.df.withColumn(\"province1\", (col(\"province\") == 1).cast(\"int\")) \\\n",
    "                    .withColumn(\"province2\", (col(\"province\") == 2).cast(\"int\"))\n",
    "        # Check that province1 and province2 are correct\n",
    "        results = df.select(\"province\", \"province1\", \"province2\").collect()\n",
    "        for row in results:\n",
    "            self.assertEqual(row[\"province1\"], 1 if row[\"province\"] == 1 else 0)\n",
    "            self.assertEqual(row[\"province2\"], 1 if row[\"province\"] == 2 else 0)\n",
    "    \n",
    "    def test_hour_extraction_and_cyclic_features(self):\n",
    "        # Test time string conversion and cyclic sin/cos calculation\n",
    "        from math import sin, cos, pi\n",
    "        HOURS_IN_DAY = 24\n",
    "\n",
    "        df = self.df.withColumn(\"hour\", (col(\"time\") / 100).cast(\"int\"))\n",
    "        df = df.withColumn(\"hoursin\", sin(2 * pi * col(\"hour\") / HOURS_IN_DAY)) \\\n",
    "               .withColumn(\"hourcos\", cos(2 * pi * col(\"hour\") / HOURS_IN_DAY))\n",
    "    \n",
    "        result = df.select(\"time\", \"hour\", \"hoursin\", \"hourcos\").collect()\n",
    "        for row in result:\n",
    "            expected_hour = row[\"time\"] // 100\n",
    "            self.assertEqual(row[\"hour\"], expected_hour)\n",
    "            # Values for hoursin and hourcos should be valid floats\n",
    "            self.assertIsInstance(row[\"hoursin\"], float)\n",
    "            self.assertIsInstance(row[\"hourcos\"], float)\n",
    "\n",
    "    def test_cyclical_day_encoding(self):\n",
    "        # You can create a small bulk test for cyclical day encoding if implemented similarly\n",
    "        pass\n",
    "    \n",
    "    def test_null_imputation(self):\n",
    "        # Create DataFrame with nulls and apply your null impute logic,\n",
    "        # then check that nulls are filled properly\n",
    "        data_with_nulls = [(None, 1.0), (2.0, None)]\n",
    "        df_null = self.spark.createDataFrame(data_with_nulls, [\"type_indexed\", \"size_value\"])\n",
    "        fill_values = {\"type_indexed\": 9999.0, \"size_value\": 0.0}\n",
    "        df_filled = df_null.fillna(fill_values)\n",
    "        for row in df_filled.collect():\n",
    "            self.assertIsNotNone(row[\"type_indexed\"])\n",
    "            self.assertIsNotNone(row[\"size_value\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sales_test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
